---
---
title: "class-trajectory"
author: "Stanislas Rigal"
date: "20 juin 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data


```{r data}
X <- c(1:20)
set.seed(1)
Y <- c(0.2*X^2+X+rnorm(20, mean = 0, sd = 10))
```

## Function

```{r core function}
class.trajectory <- function (Y = NULL, X = NULL, dataset = NULL, interval_size = 0.5)
{
  if (is.null(Y) == TRUE & is.null(Y) == TRUE & is.null(dataset) == TRUE){
    stop("either 'dataset' or at least 'Y' and 'X' must be specified")
  }
  if (is.null(Y) == TRUE & is.null(Y) == TRUE) {
    Y <- dataset[,1]
    X <- dataset[,2]
  }else{
    if (class(Y) == "character" & class(X) == "character") {
      if (is.null(dataset) == TRUE) {
        stop("if 'Y' and 'X' are character, 'dataset' must exist")
      }else{
        Y <- dataset[,Y]
        X <- dataset[,X]
      }
    }else{
      if (!(class(Y) %in% c("numeric","integer")) == TRUE & !(class(X) %in% c("numeric","integer")) == TRUE) {stop("'Y' and 'X' must be either characters or vector but 'class' must be similar")}
    }
  }
  
  data <- data.frame(cbind(Y,X))
  data <- data[order(data$X),]                                                                      # ordering the X values
  
  if (length(X)<4){
    stop("time series length must be at least 4")
  }
  
  Y <- data$Y
  X <- data$X
  
  linear.model <- lm(Y~X)
  
  orthogonal_polynomial <- lm(Y~poly(X,2, raw=F))                                                   # After getting Y = gamma*chi + delta*X' + epsilon with orthogonal polynomial
                                                                                                    # we have to perform a variable change to obtain relevant values in the X interval 
                                                                                                    # for first_order_coefficient, second_order_coefficient and intercept,
                                                                                                    # knowing that X'= alpha*X + beta 
                                                                                                    # and chi = eta*X'^2 + theta
  
  gammab  <-  orthogonal_polynomial$coefficients[3]
  delta  <-  orthogonal_polynomial$coefficients[2]
  epsilon  <-  orthogonal_polynomial$coefficients[1]
  
  alpha  <-  lm(orthogonal_polynomial$model[,2][,1]~X)$coef[2]
  beta  <-  lm(orthogonal_polynomial$model[,2][,1]~X)$coef[1]
  
  eta  <-  1/lm((orthogonal_polynomial$model[,2][,1])^2~orthogonal_polynomial$model[,2][,2])$coef[2]
  theta  <-  (-lm((orthogonal_polynomial$model[,2][,1])^2~orthogonal_polynomial$model[,2][,2])$coef[1])*eta
  
  Y2<-Y*(max(X)-min(X))/(max(Y)-min(Y))                                                             # p2 and p3 are relevant when Y and X amplitudes are equivalent,
                                                                                                    # in particular when studying scaled-to-1 indices, Y and X amplitudes
                                                                                                    # may be very different, so we scaled the amplitudes to calculate p2 and p3 
  polynomial_orthonormal_basis<-lm(Y2~poly(X,2, raw=T))$coefficients
  
  if(summary(orthogonal_polynomial)$coefficients[3,4] <= 0.05){                                     # non linear case
    classification <- data.frame(first_order_coefficient = (delta+2*beta*gammab*eta)*alpha,
                           first_order_pvalue = summary(orthogonal_polynomial)$coefficients[2,4],
                           second_order_coefficient = (alpha^2)*gammab*eta,
                           second_order_pvalue = summary(orthogonal_polynomial)$coefficients[3,4],
                           strd_error=summary(orthogonal_polynomial)$coefficients[2,2],
                           intercept = epsilon+beta*delta+(beta^2)*gammab*eta+gammab*theta,
                           x_m = (X[length(X)]-X[1])/2+X[1],
                           p1 = -(delta+2*beta*gammab*eta)/(2*alpha*gammab*eta),                    # points of interest
                           p2 = (-polynomial_orthonormal_basis[2]+1)/(2*polynomial_orthonormal_basis[3]),
                           p3 = (-polynomial_orthonormal_basis[2]-1)/(2*polynomial_orthonormal_basis[3]))
  }else{                                                                                            # linear case
    classification <- data.frame(first_order_coefficient = delta*alpha,
                           first_order_pvalue = summary(orthogonal_polynomial)$coefficients[2,4],
                           second_order_coefficient = 0,
                           second_order_pvalue = summary(orthogonal_polynomial)$coefficients[3,4],
                           strd_error=summary(orthogonal_polynomial)$coefficients[2,2],
                           intercept = epsilon+delta*beta,
                           x_m = (X[length(X)]-X[1])/2+X[1],
                           p1 = NA,
                           p2 = NA,
                           p3 = NA)
  }
  
  classification$r.sq <- summary(orthogonal_polynomial)$adj.r.squared                                # retrieve the adjusted coefficient of determination
  
  # compute the derivaive at xm-delta and at xm + delta with delta being half of the input interval size
  derivative  <-  2*(classification$x_m-(X[length(X)]-X[1])*(interval_size/2))*classification$second_order_coefficient+classification$first_order_coefficient
  derivative2  <-  2*(classification$x_m+(X[length(X)]-X[1])*(interval_size/2))*classification$second_order_coefficient+classification$first_order_coefficient
  
  
  if(sign(derivative) != sign(derivative2)){                                                        # non consistent direction around x_m
    classification$derivative  <-  NA
    classification$intercept_derivative  <-  NA
  }else{                                                                                            # consistent direction around x_m
    classification$derivative  <-  mean(c(derivative, derivative2))
    classification$intercept_derivative  <-  (classification$second_order_coefficient*classification$x_m^2+classification$first_order_coefficient*classification$x_m+classification$intercept)-classification$x_m*classification$derivative
  }
  
 # compute the derivative of the curvature function
  classification$derivated_curvature  <-  -12*(classification$second_order_coefficient^2)*(2*classification$second_order_coefficient*classification$x_m+classification$first_order_coefficient)*(classification$second_order_coefficient/abs(classification$second_order_coefficient))/
    ((1+(2*classification$second_order_coefficient*classification$x_m+classification$first_order_coefficient)^2)^(2.5))
  
  if(classification$second_order_pvalue>0.05){classification$derivated_curvature <- NA}
  
  classification$direction <- NA                                                                    # classify the direction
  classification$direction[which(classification$derivative > 0)] <- "increase"
  classification$direction[which(classification$derivative < 0)] <- "decrease"
  classification$direction[which(is.na(classification$derivative))] <- "stable"
  classification$direction[which(as.numeric(classification$first_order_pvalue)>0.05 & as.numeric(classification$second_order_pvalue)>0.05)] <- "stable"
  
  classification$acceleration <- NA                                                                 # classify the acceleration
  classification$acceleration[which(classification$derivated_curvature < 0)] <- "accelerating"
  classification$acceleration[which(classification$derivated_curvature > 0)] <- "decelerating"
  classification$acceleration[which(classification$direction == "stable" &
                                     classification$second_order_coefficient < 0)] <- "up_down"
  classification$acceleration[which(classification$direction == "stable" &
                                     classification$second_order_coefficient > 0)] <- "down_up"
  classification$acceleration[which(is.na(classification$derivated_curvature))] <- "constant"
  
  classification$shape_class <- paste(classification$direction,                                       # give the final classification combining direction and acceleration
                                classification$acceleration,
                                sep="_")
  
  linear.model.summary <- summary(linear.model)                                                       # provide the linear approach results for comparison
  
  classification$linear_slope <- linear.model.summary$coefficients[2,1]
  classification$linear_slope_pvalue <- linear.model.summary$coefficients[2,4]
  classification$linear_intercept <- linear.model.summary$coefficients[1,1]
  
  classification$first_X_value <- X[1]
  classification$last_X_value <- X[length(X)]
  
  row.names(classification)<-"Y"
  
  return(classification)
  
}
```

## Results

```{r use fonction}
classification <- class.trajectory(Y,X) # or class.trajectory(dataset = data.frame(Y, X))
classification
```



```{r plot, echo=FALSE}
plot(Y~X)
curve(classification$second_order_coefficient*x^2+classification$first_order_coefficient*x+classification$intercept, add=T)
curve(classification$linear_slope*x+classification$linear_intercept, add=T)
title("Second order polynomial and linear fits of Y")
```

## Data with sampling error


```{r data with sampling error}
X <- c(1989:2017)
set.seed(1)
Y <- c(0.1*X^2-400*X+400100+rnorm(length(X), mean = 0, sd = 3))
Y_SE<-abs(rnorm(length(X), mean = 0.05*(max(Y)-min(Y)), sd = 0.005*(max(Y)-min(Y))))
dataset<-data.frame(Index=Y,Year=X,Index_SE=Y_SE)
```

## Functions

```{r Monte Carlo simulation}
mc_trend<-function(dataset, # data
                   niter, # number of MC simulations
                   ref_year=NULL) # reference year, by default equal to the mid year of the interval
  {
  
  b<-data.frame(t(rep(NA,8)))
  attributes(b)$names<-c("second_order_coefficient",
                         "first_order_coefficient",
                         "strd_error",
                         "shape_class",
                         "intercept",
                         "p_1",
                         "p_2",
                         "p_3")
 
  if(is.null(ref_year)){
    dataset$Index<-100*dataset$Index/dataset$Index[round(nrow(dataset)/2)+1] # set reference year value to 100
    dataset$Index[which(dataset$Index<=1)]<-1                                # set values < 1 to 1
    dataset$Index_SE[which(dataset$Index<=1)]<-0                             # and their SE to 0
    dataset$Index_SE<-100*dataset$Index_SE/dataset$Index[round(nrow(dataset)/2)+1]
    dataset$sd<-dataset$Index_SE/dataset$Index                               # SE of log transformed data
    dataset$log<-log(dataset$Index)                                          # log transforme Y
  }else{
    dataset$Index<-100*dataset$Index/dataset$Index[which(dataset$Year==ref_year)]
    dataset$Index[which(dataset$Index<=1)]<-1
    dataset$Index_SE[which(dataset$Index<=1)]<-0
    dataset$Index_SE<-100*dataset$Index_SE/dataset$Index[which(dataset$Year==ref_year)]
    dataset$sd<-dataset$Index_SE/dataset$Index
    dataset$log<-log(dataset$Index)
  }
  
  for(j in 1:nrow(dataset)){
    if(dataset$sd[j]>(dataset$log[j])){dataset$sd[j]<-(dataset$log[j])}      # set SE to value amlitude if SE > value (if not, it leads to huge values when resampling in the next loop)
  }
  
  for(i in 1:niter){
    
    a<-rnorm(nrow(dataset), mean=dataset$log, sd=dataset$sd)                 # simulate Y values from normal distribution (mean= original Y value, sd = original SE)
    
    if(is.null(ref_year)){
      a<-exp(a)/exp(a[round(nrow(dataset)/2)+1])*100                         # set reference year value to 100
      }else{a<-exp(a)/exp(a[which(dataset$Year==ref_year)])*100}
    
    #a<-rnorm(nrow(dataset), mean=dataset$Index, sd=dataset$Index_SE)
    a<-class.trajectory(a,dataset$Year)
    b[i,1]<-a$second_order_coefficient
    b[i,2]<-a$first_order_coefficient
    b[i,3]<-a$strd_error
    b[i,4]<-a$shape_class
    b[i,5]<-a$intercept
    if(a$second_order_coefficient!=0){
      if(findInterval(a$p1, c(min(dataset$Year),max(dataset$Year))) == 1){ # record changing point inside time series
        b[i,6]<-a$p1}else{b[i,6]<-NA}
      if(findInterval(a$p2, c(min(dataset$Year),max(dataset$Year))) == 1){
        b[i,7]<-a$p2}else{b[i,7]<-NA}
      if(findInterval(a$p3, c(min(dataset$Year),max(dataset$Year))) == 1){
        b[i,8]<-a$p3}else{b[i,8]<-NA}
    }else{
      b[i,6]<-NA
      b[i,7]<-NA
      b[i,8]<-NA
    }
  }
  b[,4]<-as.factor(b[,4])
  return(b)
}
```


```{r classification with MC}
require(RVAideMemoire)

res_trend<-function(dataset,niter){
  
  if(nrow(dataset)>3 & anyNA(dataset$Index_SE)==FALSE){
  
    simulated<-mc_trend(dataset,niter)
    
    if(length(levels(simulated$shape_class))>1){                           # test the significance of the most numerous class
      test<-multinomial.theo.multcomp(simulated$shape_class,p=rep(1/length(levels(simulated$shape_class)),
                                                           length(levels(simulated$shape_class))),prop=TRUE)
      if(min(test$p.value2[test$observed>test$expected])<0.05){
        max_shape<-row.names(test$p.value)[which(test$observed==max(test$observed[test$observed>test$expected]))]
      }else{                                                               # if non significant class, the linear one is chosen
        max_shape<-c("increase_constant","decrease_constant","stable_constant")[which.max(c(length(grep("increase",simulated$shape_class)),
                                                                                            length(grep("decrease",simulated$shape_class)),
                                                                                            length(grep("stable",simulated$shape_class))))]
          }
    }

    if(length(levels(simulated$shape_class))==1){max_shape<-levels(simulated$shape_class)}
    
    alpha2<-mean(as.numeric(simulated[simulated$shape_class==max_shape,1]))
    sd_alpha2<-sd(as.numeric(simulated[simulated$shape_class==max_shape,1]))
    alpha1<-mean(as.numeric(simulated[simulated$shape_class==max_shape,2]))
    sd_alpha1<-sd(as.numeric(simulated[simulated$shape_class==max_shape,2]))
    inter<-mean(as.numeric(simulated[simulated$shape_class==max_shape,5]))
    strd<-mean(as.numeric(simulated[simulated$shape_class==max_shape,3]))
    p_1<-mean(as.numeric(simulated[simulated$shape_class==max_shape,6]), na.rm=T)
    sd_p_1<-sd(as.numeric(simulated[simulated$shape_class==max_shape,6]), na.rm=T)
    p_2<-mean(as.numeric(simulated[simulated$shape_class==max_shape,7]), na.rm=T)
    sd_p_2<-sd(as.numeric(simulated[simulated$shape_class==max_shape,7]), na.rm=T)
    p_3<-mean(as.numeric(simulated[simulated$shape_class==max_shape,8]), na.rm=T)
    sd_p_3<-sd(as.numeric(simulated[simulated$shape_class==max_shape,8]), na.rm=T)
    
  }else{alpha2<-alpha1<-sd_alpha1<-inter<-strd<-p_1<-sd_p_1<-p_2<-sd_p_2<-p_3<-sd_p_3<-max_shape<-NA}
  
  
  
  return(data.frame(alpha2, alpha1,sd_alpha1, inter, strd, p_1, sd_p_1, p_2, sd_p_2, p_3, sd_p_3, max_shape=as.factor(max_shape)))
}

```

## Results for data with sampling error

```{r plot2, echo=FALSE}
require(ggplot2)

example<-res_trend(dataset,1000)

dataset$Index<-dataset$Index*100/dataset$Index[round(nrow(dataset)/2)+1]

ggplot(dataset, aes(x = Year, y = Index))+
    geom_point() + theme_gray(base_size = 20)+
    labs(x ="Year", y = "Relative abundance")+
    stat_function(fun = function(x){example$alpha2*x^2+example$alpha1*x+example$inter})+
    stat_function(fun = function(x){example$alpha2*x^2+example$alpha1*x+example$inter-1.96*example$strd},linetype="dashed")+
    stat_function(fun = function(x){example$alpha2*x^2+example$alpha1*x+example$inter+1.96*example$strd},linetype="dashed")+
    geom_vline(xintercept=example$p_1, color="red")+
    geom_vline(xintercept=example$p_1+1.96*example$sd_p_1, color="red", linetype="dashed")+
    geom_vline(xintercept=example$p_1-1.96*example$sd_p_1, color="red", linetype="dashed")+
    geom_vline(xintercept=example$p_2, color="blue")+
    geom_vline(xintercept=example$p_2+1.96*example$sd_p_2, color="blue", linetype="dashed")+
    geom_vline(xintercept=example$p_2-1.96*example$sd_p_2, color="blue", linetype="dashed")+
    geom_vline(xintercept=example$p_3, color="blue")+
    geom_vline(xintercept=example$p_3+1.96*example$sd_p_3, color="blue", linetype="dashed")+
    geom_vline(xintercept=example$p_3-1.96*example$sd_p_3, color="blue", linetype="dashed")
```


